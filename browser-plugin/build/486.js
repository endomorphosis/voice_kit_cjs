"use strict";(self.webpackChunkbrowser_extension=self.webpackChunkbrowser_extension||[]).push([[486],{486:(e,o,a)=>{a.r(o),a.d(o,{MODEL_PATHS:()=>t,initializeModel:()=>r,modelLoader:()=>s});var n=a(470);const t={"Xenova/whisper-small":{files:["preprocessor_config.json","tokenizer.json","tokenizer_config.json","config.json","decoder_model_merged.onnx","encoder_model.onnx"],type:"automatic-speech-recognition"},"Xenova/gpt2-small":{files:["tokenizer.json","tokenizer_config.json","config.json","model.onnx"],type:"text-generation"}};n._K2.allowRemoteModels=!0,n._K2.useBrowserCache=!0,n._K2.useCustomCache=!0,n._K2.localModelPath=chrome.runtime.getURL("models"),n._K2.cacheDir=chrome.runtime.getURL("models"),n._K2.useFS=!1,n._K2.wasmPath=chrome.runtime.getURL("wasm/"),n._K2.remoteHost="https://huggingface.co";const s=new class{constructor(){this.cache=new Map}async loadModel(e,o){if(!t[e])throw new Error(`Model ${e} not found`);const a=await this.getModelFiles(e),s=await n._K2.loadModel(a,o);return this.cache.set(e,s),s}async getModelFiles(e){const o=t[e];return await Promise.all(o.files.map((async e=>{const o=await fetch(`${n._K2.localModelPath}/${e}`);if(!o.ok)throw new Error(`Failed to load ${e}`);return o.arrayBuffer()})))}async hasModel(e){return this.cache.has(e)}clearCache(){this.cache.clear()}};async function r(){await s.loadModel("Xenova/whisper-small"),await s.loadModel("Xenova/gpt2-small")}}}]);