(self.webpackChunkbrowser_extension=self.webpackChunkbrowser_extension||[]).push([[486,896],{144:()=>{},747:()=>{},591:()=>{},162:()=>{},405:()=>{},33:()=>{},359:()=>{},486:(e,o,s)=>{"use strict";s.d(o,{modelLoader:()=>a});var t=s(470);const n={"Xenova/whisper-small":{files:["preprocessor_config.json","tokenizer.json","tokenizer_config.json","config.json","decoder_model_merged.onnx","encoder_model.onnx"],type:"automatic-speech-recognition"},"Xenova/gpt2-small":{files:["tokenizer.json","tokenizer_config.json","config.json","model.onnx"],type:"text-generation"}};t._K2.allowRemoteModels=!0,t._K2.useBrowserCache=!0,t._K2.useCustomCache=!0,t._K2.localModelPath=chrome.runtime.getURL("models"),t._K2.cacheDir=chrome.runtime.getURL("models"),t._K2.useFS=!1,t._K2.wasmPath=chrome.runtime.getURL("wasm/"),t._K2.remoteHost="https://huggingface.co";const a=new class{constructor(){this.cache=new Map}async loadModel(e,o){if(!n[e])throw new Error(`Model ${e} not found`);const s=await this.getModelFiles(e),a=await t._K2.loadModel(s,o);return this.cache.set(e,a),a}async getModelFiles(e){const o=n[e];return await Promise.all(o.files.map((async e=>{const o=await fetch(`${t._K2.localModelPath}/${e}`);if(!o.ok)throw new Error(`Failed to load ${e}`);return o.arrayBuffer()})))}async hasModel(e){return this.cache.has(e)}clearCache(){this.cache.clear()}}}}]);